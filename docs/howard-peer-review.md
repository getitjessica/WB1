# Requirements of a Peer Review

This document outlines the multiple steps involved in peer reviewing this data good. 

## Objective of the peer review

The main goal of this peer review is to make the Data Good readable, reproducible and reusable. Additionally, the Data Lab is trying to improve our new method of disseminating Data Goods - using Jupyter Books hosted on GitHub. The vision for this method is that the code and documentation are presented as a singular unit making it easy for technical staff and country office experts to access the results from open source and proprietary data.  

While we hope that you can help make our code better, any feedback on improving the final deliverable is highly appreciated. 

## Scope of review

The scope of this review contains the code created by our colleagues to produce different indicators, the documentation of the code and the results as seen in the Jupyter Book.  

* **Code**: GitHub Repository. In your case it is  [Data Goods Training](https://github.com/worldbank/data-good-training) 
* **Public facing Data Good**: A Jupyter Book where most of the code is hidden acts as an easy-to-read face of the Data Good. You can find that [here](https://worldbank.github.io/data-good-training/README.html). 
* **Data Access**: Open data should already be accessible to you using the links provided in the Foundational Datasets section. Data access to SharePoint/AWS buckets will be provided to you by the Data lab team 

In case youâ€™re having any issues accessing the resources, please write to [datalab@worldbank.org](mailto:datalab@worldbank.org). 

## Logistics of the review

The peer review will take place on GitHub, akin to [Journal of Open Source Software](https://github.com/openjournals/joss-reviews/issues). This is to ensure that the review is openly accessible, collaborative, transparent and iterative. This will also allow us to give due credit to the reviewer (you!) for all their work. 

The steps to follow to provide an effective peer review on GitHub are outlined in the Peer Reviewing a _Data Good_ on GitHub page. Please ensure you follow the steps to get used to using GitHub as a mechanism to conduct your review.

## Criteria for the review

Once you have your prerequisites, you can use the following criteria to conduct your review. Please note that these are guiding questions. In case you have additional feedback, or want to follow different questions to achieve the same objectives of readability, reproducibility and reusability, please feel free to use them. 

Following are some resources you can use to familiarize yourself with the peer review process 

* https://www.pyopensci.org/software-peer-review/how-to/reviewer-guide.html

### I. Readability

Readability is to check if the existing, data, code and documentation can be understood by the person reading it. 

This step means that you are able to read the code and tell exactly what it is doing. For this, the code should be well commented. Similarly, when you read the documentation, as someone who does not understand Nighttime Lights in Gaza or Air Pollution in Lebanon, you should atleast get a sense of the methodology being used. Here are a few checks you can use to check the readability of the code -



1. 

### II. Reproducibility Check

Reproducibility is when you can take the code we shared with you and run it on your own without any glitches. Ideally, you should be able to install the required libraries, press play and watch the visualizations unfold. However, 

### III. Reusability Check
